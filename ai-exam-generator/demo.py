#!/usr/bin/env python3
"""
Script demo/test h·ªá th·ªëng v·ªõi data m·∫´u
Kh√¥ng c·∫ßn PDF th·∫≠t, t·ª± t·∫°o data gi·∫£ l·∫≠p
"""
import json
from pathlib import Path
from loguru import logger

from src.models import (
    Document, DocumentPage, DocumentMetadata,
    GlobalConfig, CognitiveRatios, DifficultyRatios,
    Blueprint, Topic, LearningOutcome, SourceTrace
)
from src.config import get_config
from src.rag_indexer import TextChunker, RAGIndexer
from src.generators import MatrixGenerator, QuestionGenerator
from src.validator import ExamValidator
from src.exporter import DOCXExporter, ExportRequest


def create_sample_document():
    """T·∫°o document m·∫´u (gi·∫£ l·∫≠p PDF ƒë√£ parse)"""
    logger.info("üìÑ T·∫°o document m·∫´u...")
    
    sample_text = """
CH∆Ø∆†NG 1: H·ªÜ PH∆Ø∆†NG TR√åNH B·∫¨C NH·∫§T HAI ·∫®N

I. M·ª§C TI√äU
- H·ªçc sinh bi·∫øt kh√°i ni·ªám h·ªá ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t hai ·∫©n
- H·ªçc sinh hi·ªÉu v√† gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh b·∫±ng ph∆∞∆°ng ph√°p th·∫ø
- H·ªçc sinh hi·ªÉu v√† gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh b·∫±ng ph∆∞∆°ng ph√°p c·ªông ƒë·∫°i s·ªë
- V·∫≠n d·ª•ng gi·∫£i b√†i to√°n b·∫±ng c√°ch l·∫≠p h·ªá ph∆∞∆°ng tr√¨nh

II. Y√äU C·∫¶U C·∫¶N ƒê·∫†T
1. Nh·∫≠n bi·∫øt ƒë∆∞·ª£c h·ªá ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t hai ·∫©n
2. Gi·∫£i th√≠ch ƒë∆∞·ª£c nghi·ªám c·ªßa h·ªá ph∆∞∆°ng tr√¨nh
3. Gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh b·∫±ng ph∆∞∆°ng ph√°p th·∫ø
4. Gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh b·∫±ng ph∆∞∆°ng ph√°p c·ªông ƒë·∫°i s·ªë
5. V·∫≠n d·ª•ng gi·∫£i b√†i to√°n th·ª±c t·∫ø b·∫±ng c√°ch l·∫≠p h·ªá ph∆∞∆°ng tr√¨nh

III. N·ªòI DUNG
- Kh√°i ni·ªám h·ªá ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t hai ·∫©n
- Nghi·ªám c·ªßa h·ªá ph∆∞∆°ng tr√¨nh
- Ph∆∞∆°ng ph√°p gi·∫£i: ph∆∞∆°ng ph√°p th·∫ø, ph∆∞∆°ng ph√°p c·ªông ƒë·∫°i s·ªë
- ·ª®ng d·ª•ng: gi·∫£i b√†i to√°n b·∫±ng c√°ch l·∫≠p h·ªá ph∆∞∆°ng tr√¨nh

CH∆Ø∆†NG 2: H√ÄM S·ªê B·∫¨C NH·∫§T

I. M·ª§C TI√äU
- H·ªçc sinh bi·∫øt kh√°i ni·ªám h√†m s·ªë b·∫≠c nh·∫•t
- H·ªçc sinh hi·ªÉu t√≠nh ch·∫•t c·ªßa h√†m s·ªë b·∫≠c nh·∫•t
- V·∫Ω ƒë·ªì th·ªã h√†m s·ªë b·∫≠c nh·∫•t

II. Y√äU C·∫¶U C·∫¶N ƒê·∫†T
1. Nh·∫≠n bi·∫øt h√†m s·ªë b·∫≠c nh·∫•t
2. X√°c ƒë·ªãnh t√≠nh ƒë·ªìng bi·∫øn, ngh·ªãch bi·∫øn c·ªßa h√†m s·ªë b·∫≠c nh·∫•t
3. V·∫Ω ƒë·ªì th·ªã h√†m s·ªë y = ax + b
4. V·∫≠n d·ª•ng gi·∫£i b√†i to√°n li√™n quan ƒë·∫øn h√†m s·ªë b·∫≠c nh·∫•t
"""
    
    doc = Document(
        doc_id="demo-001",
        file_name="de_cuong_toan_9_demo.pdf",
        metadata=DocumentMetadata(
            subject="To√°n",
            grade=9,
            term="I",
            school_year="2024-2025"
        ),
        pages=[
            DocumentPage(page=1, text=sample_text, tables=[], images=[])
        ]
    )
    
    return doc


def create_sample_blueprint():
    """T·∫°o blueprint m·∫´u (c√≥ th·ªÉ d√πng khi kh√¥ng c√≥ OpenAI)"""
    logger.info("üß† T·∫°o blueprint m·∫´u...")
    
    return Blueprint(
        subject="To√°n",
        grade=9,
        term="I",
        topics=[
            Topic(
                topic_id="T1",
                name="H·ªá ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t hai ·∫©n",
                outcomes=[
                    LearningOutcome(
                        outcome_id="O1",
                        verb="nh·∫≠n bi·∫øt",
                        statement="Nh·∫≠n bi·∫øt ƒë∆∞·ª£c h·ªá ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t hai ·∫©n",
                        cognitive_level_hint=["biet"],
                        source_trace=[SourceTrace(chunk_id="p1_c001", page=1)]
                    ),
                    LearningOutcome(
                        outcome_id="O2",
                        verb="gi·∫£i",
                        statement="Gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh b·∫±ng ph∆∞∆°ng ph√°p th·∫ø",
                        cognitive_level_hint=["hieu", "vandung"],
                        source_trace=[SourceTrace(chunk_id="p1_c002", page=1)]
                    ),
                    LearningOutcome(
                        outcome_id="O3",
                        verb="v·∫≠n d·ª•ng",
                        statement="V·∫≠n d·ª•ng gi·∫£i b√†i to√°n th·ª±c t·∫ø b·∫±ng c√°ch l·∫≠p h·ªá ph∆∞∆°ng tr√¨nh",
                        cognitive_level_hint=["vandung", "vandungcao"],
                        source_trace=[SourceTrace(chunk_id="p1_c003", page=1)]
                    )
                ],
                keywords=["h·ªá ph∆∞∆°ng tr√¨nh", "ph∆∞∆°ng ph√°p th·∫ø", "ph∆∞∆°ng ph√°p c·ªông"],
                subtopics=["Kh√°i ni·ªám", "Gi·∫£i h·ªá", "·ª®ng d·ª•ng"]
            ),
            Topic(
                topic_id="T2",
                name="H√†m s·ªë b·∫≠c nh·∫•t",
                outcomes=[
                    LearningOutcome(
                        outcome_id="O4",
                        verb="nh·∫≠n bi·∫øt",
                        statement="Nh·∫≠n bi·∫øt h√†m s·ªë b·∫≠c nh·∫•t",
                        cognitive_level_hint=["biet"],
                        source_trace=[SourceTrace(chunk_id="p1_c004", page=1)]
                    ),
                    LearningOutcome(
                        outcome_id="O5",
                        verb="v·∫Ω",
                        statement="V·∫Ω ƒë·ªì th·ªã h√†m s·ªë y = ax + b",
                        cognitive_level_hint=["hieu", "vandung"],
                        source_trace=[SourceTrace(chunk_id="p1_c005", page=1)]
                    )
                ],
                keywords=["h√†m s·ªë b·∫≠c nh·∫•t", "ƒë·ªì th·ªã", "t√≠nh ƒë·ªìng bi·∫øn"],
                subtopics=["Kh√°i ni·ªám", "ƒê·ªì th·ªã", "T√≠nh ch·∫•t"]
            )
        ]
    )


def main():
    """Ch·∫°y demo"""
    logger.info("=" * 80)
    logger.info("üéØ DEMO H·ªÜ TH·ªêNG - KH√îNG C·∫¶N PDF")
    logger.info("=" * 80)
    
    try:
        # Load config
        config = get_config()
        output_dir = Path("outputs/demo")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. T·∫°o document m·∫´u
        document = create_sample_document()
        logger.info(f"‚úì T·∫°o document: {document.file_name}")
        
        # 2. Chunking
        logger.info("\nüì¶ Chunking...")
        chunker = TextChunker(chunk_size=500, chunk_overlap=100)
        chunks = chunker.chunk_document(document)
        logger.info(f"‚úì T·∫°o {len(chunks)} chunks")
        
        # 3. RAG Index
        logger.info("\nüîç Build RAG index...")
        indexer = RAGIndexer()
        indexer.build_index(chunks)
        logger.info("‚úì Index ho√†n t·∫•t")
        
        # 4. Blueprint (d√πng m·∫´u thay v√¨ g·ªçi AI)
        logger.info("\nüß† Load blueprint m·∫´u...")
        blueprint = create_sample_blueprint()
        logger.info(f"‚úì Blueprint: {len(blueprint.topics)} topics")
        
        # 5. Ma tr·∫≠n (g·ªçi AI)
        logger.info("\nüìä Sinh ma tr·∫≠n...")
        global_cfg = GlobalConfig(
            time_minutes=45,
            total_points=10.0,
            mcq_ratio=0.6,
            essay_ratio=0.4
        )
        cognitive_cfg = CognitiveRatios(biet=0.3, hieu=0.3, vandung=0.3, vandungcao=0.1)
        difficulty_cfg = DifficultyRatios(de=0.3, tb=0.4, kho=0.3)
        
        matrix_gen = MatrixGenerator()
        matrix = matrix_gen.generate(blueprint, global_cfg, cognitive_cfg, difficulty_cfg)
        logger.info(f"‚úì Ma tr·∫≠n: {len(matrix.items_plan)} rows")
        
        # 6. Sinh c√¢u h·ªèi
        logger.info("\nüìù Sinh c√¢u h·ªèi...")
        question_gen = QuestionGenerator(indexer=indexer)
        exam = question_gen.generate_exam(matrix, blueprint)
        exam.title = "ƒê·ªÄ KI·ªÇM TRA TO√ÅN 9 (DEMO)"
        exam.subject = "To√°n"
        exam.grade = 9
        exam.time_minutes = 45
        exam.total_points = 10.0
        logger.info(f"‚úì ƒê√£ sinh {len(exam.questions)} c√¢u h·ªèi")
        
        # 7. Validate
        logger.info("\n‚úÖ Validation...")
        validator = ExamValidator()
        result = validator.validate(exam)
        logger.info(f"‚úì Valid: {result.is_valid}, Issues: {len(result.issues)}")
        
        # 8. Export
        logger.info("\nüìÑ Export DOCX...")
        exporter = DOCXExporter()
        export_request = ExportRequest(
            exam=exam,
            matrix=matrix,
            blueprint=blueprint,
            include_answer_key=True,
            include_rubric=True
        )
        
        docx_path = output_dir / "demo_exam.docx"
        exporter.export(export_request, str(docx_path))
        logger.info(f"‚úì File: {docx_path}")
        
        # Save JSON
        with open(output_dir / "blueprint.json", 'w', encoding='utf-8') as f:
            json.dump(blueprint.model_dump(), f, ensure_ascii=False, indent=2, default=str)
        
        with open(output_dir / "matrix.json", 'w', encoding='utf-8') as f:
            json.dump(matrix.model_dump(), f, ensure_ascii=False, indent=2)
        
        with open(output_dir / "exam.json", 'w', encoding='utf-8') as f:
            json.dump(exam.model_dump(), f, ensure_ascii=False, indent=2, default=str)
        
        logger.info("\n" + "=" * 80)
        logger.info("‚ú® DEMO HO√ÄN T·∫§T!")
        logger.info("=" * 80)
        logger.info(f"üìÅ Output: {output_dir}")
        logger.info(f"üìù ƒê·ªÅ thi: {docx_path}")
        logger.info("=" * 80)
        
    except Exception as e:
        logger.exception(f"‚ùå L·ªói: {e}")


if __name__ == "__main__":
    main()
