"""
Module ki·ªÉm tra ch·∫•t l∆∞·ª£ng c√¢u h·ªèi v√† ƒë·ªÅ ki·ªÉm tra
"""
import re
from typing import List, Set, Dict, Any
from loguru import logger
from rapidfuzz import fuzz

from .models import Exam, Question, ValidationIssue, ValidationResult


class ExamValidator:
    """Validate ch·∫•t l∆∞·ª£ng ƒë·ªÅ ki·ªÉm tra"""
    
    def __init__(self, similarity_threshold: float = 0.8):
        """
        Args:
            similarity_threshold: Ng∆∞·ª°ng similarity ƒë·ªÉ coi l√† tr√πng l·∫∑p
        """
        self.similarity_threshold = similarity_threshold
    
    def validate(self, exam: Exam) -> ValidationResult:
        """
        Validate ƒë·ªÅ ki·ªÉm tra
        
        Args:
            exam: ƒê·ªÅ ki·ªÉm tra c·∫ßn validate
            
        Returns:
            ValidationResult
        """
        logger.info(f"üîç Validating exam: {exam.title}")
        
        issues = []
        
        # Rule-based validation
        issues.extend(self._validate_structure(exam))
        issues.extend(self._validate_questions(exam))
        issues.extend(self._validate_duplicates(exam))
        issues.extend(self._validate_points(exam))
        
        # Stats
        stats = self._compute_stats(exam)
        
        is_valid = not any(i.severity == "error" for i in issues)
        
        result = ValidationResult(
            is_valid=is_valid,
            issues=issues,
            stats=stats
        )
        
        logger.info(f"‚úÖ Validation done: {len(issues)} issues found")
        return result
    
    def _validate_structure(self, exam: Exam) -> List[ValidationIssue]:
        """Ki·ªÉm tra c·∫•u tr√∫c c∆° b·∫£n"""
        issues = []
        
        if not exam.questions:
            issues.append(ValidationIssue(
                question_id="EXAM",
                severity="error",
                message="ƒê·ªÅ kh√¥ng c√≥ c√¢u h·ªèi n√†o"
            ))
        
        if exam.total_points <= 0:
            issues.append(ValidationIssue(
                question_id="EXAM",
                severity="error",
                message="T·ªïng ƒëi·ªÉm ph·∫£i > 0"
            ))
        
        if exam.time_minutes <= 0:
            issues.append(ValidationIssue(
                question_id="EXAM",
                severity="error",
                message="Th·ªùi gian ph·∫£i > 0"
            ))
        
        return issues
    
    def _validate_questions(self, exam: Exam) -> List[ValidationIssue]:
        """Ki·ªÉm tra t·ª´ng c√¢u h·ªèi"""
        issues = []
        
        for q in exam.questions:
            # Check stem
            if not q.stem or len(q.stem.strip()) < 10:
                issues.append(ValidationIssue(
                    question_id=q.id,
                    severity="error",
                    message="C√¢u h·ªèi qu√° ng·∫Øn ho·∫∑c tr·ªëng",
                    suggestion="Vi·∫øt l·∫°i c√¢u h·ªèi r√µ r√†ng h∆°n"
                ))
            
            # Check MCQ
            if q.type in ["mcq_single", "mcq_multiple"]:
                if not q.options or len(q.options) < 2:
                    issues.append(ValidationIssue(
                        question_id=q.id,
                        severity="error",
                        message="MCQ ph·∫£i c√≥ √≠t nh·∫•t 2 l·ª±a ch·ªçn"
                    ))
                
                if q.options and len(q.options) != len(set(q.options)):
                    issues.append(ValidationIssue(
                        question_id=q.id,
                        severity="warning",
                        message="C√≥ l·ª±a ch·ªçn tr√πng l·∫∑p"
                    ))
                
                # Check answer format
                if q.type == "mcq_single":
                    if q.answer not in ["A", "B", "C", "D", "E", "F"]:
                        issues.append(ValidationIssue(
                            question_id=q.id,
                            severity="error",
                            message=f"ƒê√°p √°n '{q.answer}' kh√¥ng h·ª£p l·ªá cho MCQ"
                        ))
                    
                    # Check if answer exists in options
                    answer_letters = ["A", "B", "C", "D", "E", "F"]
                    if q.options:
                        answer_idx = answer_letters.index(q.answer) if q.answer in answer_letters else -1
                        if answer_idx >= len(q.options):
                            issues.append(ValidationIssue(
                                question_id=q.id,
                                severity="error",
                                message=f"ƒê√°p √°n {q.answer} v∆∞·ª£t qu√° s·ªë l·ª±a ch·ªçn"
                            ))
            
            # Check answer
            if not q.answer or len(q.answer.strip()) == 0:
                issues.append(ValidationIssue(
                    question_id=q.id,
                    severity="error",
                    message="C√¢u h·ªèi kh√¥ng c√≥ ƒë√°p √°n"
                ))
            
            # Check essay rubric
            if q.type in ["short_answer", "essay"]:
                if not q.rubric:
                    issues.append(ValidationIssue(
                        question_id=q.id,
                        severity="warning",
                        message="C√¢u t·ª± lu·∫≠n n√™n c√≥ rubric"
                    ))
            
            # Check points
            if q.points <= 0:
                issues.append(ValidationIssue(
                    question_id=q.id,
                    severity="error",
                    message="ƒêi·ªÉm c√¢u h·ªèi ph·∫£i > 0"
                ))
            
            # Check source trace
            if not q.source_trace:
                issues.append(ValidationIssue(
                    question_id=q.id,
                    severity="info",
                    message="C√¢u h·ªèi kh√¥ng c√≥ truy v·∫øt ngu·ªìn"
                ))
        
        return issues
    
    def _validate_duplicates(self, exam: Exam) -> List[ValidationIssue]:
        """Ki·ªÉm tra c√¢u h·ªèi tr√πng l·∫∑p"""
        issues = []
        
        stems = [q.stem for q in exam.questions]
        
        for i, q1 in enumerate(exam.questions):
            for j, q2 in enumerate(exam.questions[i+1:], start=i+1):
                similarity = self._text_similarity(q1.stem, q2.stem)
                
                if similarity > self.similarity_threshold:
                    issues.append(ValidationIssue(
                        question_id=f"{q1.id},{q2.id}",
                        severity="warning",
                        message=f"C√¢u {q1.id} v√† {q2.id} c√≥ n·ªôi dung t∆∞∆°ng t·ª± ({similarity:.0%})",
                        suggestion="Ki·ªÉm tra v√† lo·∫°i b·ªè c√¢u tr√πng l·∫∑p"
                    ))
        
        return issues
    
    def _validate_points(self, exam: Exam) -> List[ValidationIssue]:
        """Ki·ªÉm tra t·ªïng ƒëi·ªÉm"""
        issues = []
        
        actual_total = sum(q.points for q in exam.questions)
        expected_total = exam.total_points
        
        diff = abs(actual_total - expected_total)
        
        if diff > 0.01:  # Tolerance for floating point
            issues.append(ValidationIssue(
                question_id="EXAM",
                severity="error",
                message=f"T·ªïng ƒëi·ªÉm th·ª±c t·∫ø ({actual_total}) ‚â† t·ªïng ƒëi·ªÉm khai b√°o ({expected_total})",
                suggestion=f"ƒêi·ªÅu ch·ªânh ƒëi·ªÉm c√°c c√¢u h·ªèi ƒë·ªÉ t·ªïng = {expected_total}"
            ))
        
        return issues
    
    def _compute_stats(self, exam: Exam) -> dict:
        """T√≠nh th·ªëng k√™ ƒë·ªÅ"""
        stats = {
            "total_questions": len(exam.questions),
            "total_points": sum(q.points for q in exam.questions),
            "by_type": {},
            "by_cognitive_level": {},
            "by_difficulty": {}
        }
        
        # Count by type
        for q in exam.questions:
            stats["by_type"][q.type] = stats["by_type"].get(q.type, 0) + 1
            stats["by_cognitive_level"][q.cognitive_level] = stats["by_cognitive_level"].get(q.cognitive_level, 0) + 1
            stats["by_difficulty"][q.difficulty] = stats["by_difficulty"].get(q.difficulty, 0) + 1
        
        return stats
    
    def _text_similarity(self, text1: str, text2: str) -> float:
        """T√≠nh ƒë·ªô t∆∞∆°ng t·ª± gi·ªØa 2 text"""
        # Normalize
        t1 = self._normalize_text(text1)
        t2 = self._normalize_text(text2)
        
        # Use rapidfuzz (faster than difflib)
        return fuzz.ratio(t1, t2) / 100.0
    
    def _normalize_text(self, text: str) -> str:
        """Chu·∫©n h√≥a text ƒë·ªÉ so s√°nh"""
        # Lowercase
        text = text.lower()
        
        # Remove punctuation
        text = re.sub(r'[^\w\s]', '', text)
        
        # Remove extra spaces
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
