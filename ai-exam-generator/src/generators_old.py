"""
Module sinh blueprint, matrix v√† c√¢u h·ªèi b·∫±ng AI
"""
import json
import logging
from typing import List, Optional
from openai import OpenAI

from .models import (
    Blueprint, Topic, LearningOutcome, SourceTrace,
    ExamMatrix, MatrixItem, GlobalConfig, CognitiveRatios, DifficultyRatios,
    Question, QuestionRubric, Exam, Chunk
)
from .config import get_settings
from .rag_indexer import RAGIndexer

logger = logging.getLogger(__name__)


class BlueprintGenerator:
    """Sinh blueprint ki·∫øn th·ª©c t·ª´ ƒë·ªÅ c∆∞∆°ng"""
    
    def __init__(self, client: OpenAI = None):
        settings = get_settings()
        self.client = client or OpenAI(api_key=settings.openai_api_key)
        self.model = settings.openai_model
    
    def generate(
        self,
        chunks: List[Chunk],
        subject: str = None,
        grade: int = None
    ) -> Blueprint:
        """
        Sinh blueprint t·ª´ chunks
        
        Args:
            chunks: C√°c chunks ch·ª©a n·ªôi dung ƒë·ªÅ c∆∞∆°ng
            subject: M√¥n h·ªçc
            grade: Kh·ªëi
            
        Returns:
            Blueprint object
        """
        logger.info("üß† Generating blueprint from syllabus...")
        
        # Combine text from chunks
        full_text = "\n\n".join([c.text for c in chunks])
        
        # Create prompt
        prompt = self._create_blueprint_prompt(full_text, subject, grade)
        
        # Call AI
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch ƒë·ªÅ c∆∞∆°ng gi√°o d·ª•c. Tr·∫£ v·ªÅ JSON ƒë√∫ng format."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.3
        )
        
        # Parse response
        result = json.loads(response.choices[0].message.content)
        
        # Create Blueprint object
        topics = []
        for topic_data in result.get("topics", []):
            outcomes = []
            for outcome_data in topic_data.get("outcomes", []):
                outcomes.append(LearningOutcome(
                    outcome_id=outcome_data.get("outcome_id", ""),
                    verb=outcome_data.get("verb", ""),
                    statement=outcome_data.get("statement", ""),
                    cognitive_level_hint=outcome_data.get("cognitive_level_hint", []),
                    source_trace=[]  # Will be filled later
                ))
            
            topics.append(Topic(
                topic_id=topic_data.get("topic_id", ""),
                name=topic_data.get("name", ""),
                outcomes=outcomes,
                keywords=topic_data.get("keywords", []),
                subtopics=topic_data.get("subtopics", [])
            ))
        
        blueprint = Blueprint(
            subject=result.get("subject", subject or ""),
            grade=result.get("grade", grade),
            term=result.get("term"),
            topics=topics
        )
        
        logger.info(f"‚úÖ Generated blueprint with {len(topics)} topics")
        return blueprint
    
    def _create_blueprint_prompt(
        self,
        text: str,
        subject: str = None,
        grade: int = None
    ) -> str:
        """T·∫°o prompt ƒë·ªÉ sinh blueprint"""
        
        prompt = f"""Ph√¢n t√≠ch ƒë·ªÅ c∆∞∆°ng sau v√† tr√≠ch xu·∫•t:
1. C√°c ch∆∞∆°ng/ch·ªß ƒë·ªÅ ch√≠nh
2. Y√™u c·∫ßu c·∫ßn ƒë·∫°t (outcomes) cho m·ªói ch·ªß ƒë·ªÅ
3. T·ª´ kh√≥a v√† kh√°i ni·ªám quan tr·ªçng

ƒê·ªÄ C∆Ø∆†NG:
{text[:4000]}  # Limit token

H∆Ø·ªöNG D·∫™N:
- M·ªói outcome ph·∫£i c√≥ ƒë·ªông t·ª´ r√µ r√†ng (nh·∫≠n bi·∫øt, gi·∫£i th√≠ch, v·∫≠n d·ª•ng...)
- G·ª£i √Ω m·ª©c ƒë·ªô nh·∫≠n th·ª©c: ["biet", "hieu", "vandung", "vandungcao"]
- Tr·∫£ v·ªÅ JSON theo format:

{{
  "subject": "{subject or 'M√¥n h·ªçc'}",
  "grade": {grade or 'null'},
  "term": "H·ªçc k·ª≥ I/II (n·∫øu c√≥)",
  "topics": [
    {{
      "topic_id": "T1",
      "name": "T√™n ch∆∞∆°ng/ch·ªß ƒë·ªÅ",
      "outcomes": [
        {{
          "outcome_id": "O1",
          "verb": "gi·∫£i",
          "statement": "Gi·∫£i h·ªá ph∆∞∆°ng tr√¨nh b·∫≠c nh·∫•t hai ·∫©n",
          "cognitive_level_hint": ["biet", "hieu"]
        }}
      ],
      "keywords": ["t·ª´ kh√≥a 1", "t·ª´ kh√≥a 2"],
      "subtopics": ["ch·ªß ƒë·ªÅ con 1", "ch·ªß ƒë·ªÅ con 2"]
    }}
  ]
}}
"""
        return prompt


class MatrixGenerator:
    """Sinh ma tr·∫≠n ƒë·ªÅ ki·ªÉm tra"""
    
    def __init__(self, client: OpenAI = None):
        settings = get_settings()
        self.client = client or OpenAI(api_key=settings.openai_api_key)
        self.model = settings.openai_model
    
    def generate(
        self,
        blueprint: Blueprint,
        global_config: GlobalConfig,
        cognitive_ratios: CognitiveRatios,
        difficulty_ratios: DifficultyRatios
    ) -> ExamMatrix:
        """
        Sinh ma tr·∫≠n t·ª´ blueprint
        
        Args:
            blueprint: Blueprint ki·∫øn th·ª©c
            global_config: C·∫•u h√¨nh chung (th·ªùi gian, t·ªïng ƒëi·ªÉm...)
            cognitive_ratios: T·ª∑ l·ªá m·ª©c ƒë·ªô nh·∫≠n th·ª©c
            difficulty_ratios: T·ª∑ l·ªá ƒë·ªô kh√≥
            
        Returns:
            ExamMatrix object
        """
        logger.info("üìä Generating exam matrix...")
        
        # Create prompt
        prompt = self._create_matrix_prompt(
            blueprint,
            global_config,
            cognitive_ratios,
            difficulty_ratios
        )
        
        # Call AI
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "B·∫°n l√† chuy√™n gia thi·∫øt k·∫ø ma tr·∫≠n ƒë·ªÅ ki·ªÉm tra. Tr·∫£ v·ªÅ JSON ƒë√∫ng format."},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.3
        )
        
        result = json.loads(response.choices[0].message.content)
        
        # Parse items_plan
        items = []
        for item_data in result.get("items_plan", []):
            items.append(MatrixItem(
                row_id=item_data.get("row_id", ""),
                topic_id=item_data.get("topic_id", ""),
                outcome_ids=item_data.get("outcome_ids", []),
                cognitive_level=item_data.get("cognitive_level", "biet"),
                difficulty=item_data.get("difficulty", "tb"),
                type=item_data.get("type", "mcq_single"),
                n_questions=item_data.get("n_questions", 1),
                points_each=item_data.get("points_each", 0.25),
                source_trace=[]
            ))
        
        matrix = ExamMatrix(
            global_config=global_config,
            cognitive_ratios=cognitive_ratios,
            difficulty_ratios=difficulty_ratios,
            items_plan=items
        )
        
        logger.info(f"‚úÖ Generated matrix with {len(items)} rows")
        return matrix
    
    def _create_matrix_prompt(
        self,
        blueprint: Blueprint,
        global_config: GlobalConfig,
        cognitive_ratios: CognitiveRatios,
        difficulty_ratios: DifficultyRatios
    ) -> str:
        """T·∫°o prompt sinh ma tr·∫≠n"""
        
        # Summarize blueprint
        topics_summary = "\n".join([
            f"- {t.topic_id}: {t.name} ({len(t.outcomes)} outcomes)"
            for t in blueprint.topics
        ])
        
        prompt = f"""Thi·∫øt k·∫ø ma tr·∫≠n ƒë·ªÅ ki·ªÉm tra theo y√™u c·∫ßu:

C√ÅC CH·ª¶ ƒê·ªÄ:
{topics_summary}

Y√äU C·∫¶U:
- Th·ªùi gian: {global_config.time_minutes} ph√∫t
- T·ªïng ƒëi·ªÉm: {global_config.total_points}
- T·ª∑ l·ªá tr·∫Øc nghi·ªám: {global_config.mcq_ratio * 100}%
- T·ª∑ l·ªá t·ª± lu·∫≠n: {global_config.essay_ratio * 100}%

T·ª∂ L·ªÜ M·ª®C ƒê·ªò NH·∫¨N TH·ª®C:
- Bi·∫øt: {cognitive_ratios.biet * 100}%
- Hi·ªÉu: {cognitive_ratios.hieu * 100}%
- V·∫≠n d·ª•ng: {cognitive_ratios.vandung * 100}%
- V·∫≠n d·ª•ng cao: {cognitive_ratios.vandungcao * 100}%

T·ª∂ L·ªÜ ƒê·ªò KH√ì:
- D·ªÖ: {difficulty_ratios.de * 100}%
- Trung b√¨nh: {difficulty_ratios.tb * 100}%
- Kh√≥: {difficulty_ratios.kho * 100}%

LO·∫†I C√ÇU H·ªéI:
- mcq_single: Tr·∫Øc nghi·ªám 1 ƒë√°p √°n
- mcq_multiple: Tr·∫Øc nghi·ªám nhi·ªÅu ƒë√°p √°n
- true_false: ƒê√∫ng/Sai
- fill_blank: ƒêi·ªÅn khuy·∫øt
- short_answer: T·ª± lu·∫≠n ng·∫Øn
- essay: T·ª± lu·∫≠n

Tr·∫£ v·ªÅ JSON:
{{
  "items_plan": [
    {{
      "row_id": "R1",
      "topic_id": "T1",
      "outcome_ids": ["O1", "O2"],
      "cognitive_level": "biet|hieu|vandung|vandungcao",
      "difficulty": "de|tb|kha|kho",
      "type": "mcq_single|essay|...",
      "n_questions": 2,
      "points_each": 0.25
    }}
  ]
}}

ƒê·∫¢M B·∫¢O:
- T·ªïng ƒëi·ªÉm = {global_config.total_points}
- T·ª∑ l·ªá c√°c m·ª©c ƒë·ªô g·∫ßn ƒë√∫ng y√™u c·∫ßu
- Ph√¢n b·ªï ƒë·ªÅu c√°c ch·ªß ƒë·ªÅ
"""
        return prompt


class QuestionGenerator:
    """Sinh c√¢u h·ªèi t·ª´ ma tr·∫≠n"""
    
    def __init__(self, client: OpenAI = None, indexer: RAGIndexer = None):
        settings = get_settings()
        self.client = client or OpenAI(api_key=settings.openai_api_key)
        self.model = settings.openai_model
        self.indexer = indexer
    
    def generate_exam(
        self,
        matrix: ExamMatrix,
        blueprint: Blueprint,
        title: str = "ƒê·ªÅ ki·ªÉm tra"
    ) -> Exam:
        """
        Sinh ƒë·ªÅ ki·ªÉm tra t·ª´ ma tr·∫≠n
        
        Args:
            matrix: Ma tr·∫≠n ƒë·ªÅ
            blueprint: Blueprint ki·∫øn th·ª©c
            title: Ti√™u ƒë·ªÅ ƒë·ªÅ thi
            
        Returns:
            Exam object
        """
        logger.info("üìù Generating exam questions...")
        
        all_questions = []
        question_counter = 1
        
        for item in matrix.items_plan:
            # Find topic info
            topic = next((t for t in blueprint.topics if t.topic_id == item.topic_id), None)
            
            # Generate questions for this matrix item
            questions = self._generate_questions_for_item(
                item,
                topic,
                start_id=question_counter
            )
            
            all_questions.extend(questions)
            question_counter += len(questions)
        
        exam = Exam(
            exam_id=f"exam_{blueprint.subject}_{blueprint.grade or 'X'}",
            title=title,
            subject=blueprint.subject,
            grade=blueprint.grade,
            time_minutes=matrix.global_config.time_minutes,
            total_points=matrix.global_config.total_points,
            questions=all_questions
        )
        
        logger.info(f"‚úÖ Generated {len(all_questions)} questions")
        return exam
    
    def _generate_questions_for_item(
        self,
        item: MatrixItem,
        topic: Optional[Topic],
        start_id: int
    ) -> List[Question]:
        """Sinh c√¢u h·ªèi cho m·ªôt item trong ma tr·∫≠n"""
        
        questions = []
        
        # Get context from RAG
        context = ""
        if self.indexer and topic:
            search_query = f"{topic.name} {' '.join(topic.keywords[:3])}"
            relevant_chunks = self.indexer.search(search_query, top_k=3)
            context = "\n\n".join([c.text for c in relevant_chunks])
            source_trace = self.indexer.get_source_traces(relevant_chunks)
        else:
            source_trace = []
        
        # Create prompt
        prompt = self._create_question_prompt(item, topic, context)
        
        # Call AI
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "B·∫°n l√† chuy√™n gia ra ƒë·ªÅ ki·ªÉm tra. Sinh c√¢u h·ªèi ch·∫•t l∆∞·ª£ng cao, r√µ r√†ng, kh√¥ng m∆° h·ªì."},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.7
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # Parse questions
            for i, q_data in enumerate(result.get("questions", [])[:item.n_questions]):
                rubric = None
                if item.type in ["short_answer", "essay"] and "rubric" in q_data:
                    rubric = QuestionRubric(
                        max_points=item.points_each,
                        criteria=q_data["rubric"].get("criteria", [])
                    )
                
                question = Question(
                    id=f"Q{start_id + i}",
                    type=item.type,
                    topic_id=item.topic_id,
                    cognitive_level=item.cognitive_level,
                    difficulty=item.difficulty,
                    stem=q_data.get("stem", ""),
                    options=q_data.get("options"),
                    answer=q_data.get("answer", ""),
                    explanation=q_data.get("explanation"),
                    rubric=rubric,
                    source_trace=source_trace,
                    points=item.points_each
                )
                questions.append(question)
        
        except Exception as e:
            logger.error(f"‚ùå Error generating questions: {e}")
        
        return questions
    
    def _create_question_prompt(
        self,
        item: MatrixItem,
        topic: Optional[Topic],
        context: str
    ) -> str:
        """T·∫°o prompt sinh c√¢u h·ªèi"""
        
        topic_name = topic.name if topic else "Ch·ªß ƒë·ªÅ"
        
        type_instructions = {
            "mcq_single": "4 l·ª±a ch·ªçn A/B/C/D, ch·ªâ 1 ƒë√°p √°n ƒë√∫ng",
            "mcq_multiple": "4 l·ª±a ch·ªçn, c√≥ th·ªÉ nhi·ªÅu ƒë√°p √°n ƒë√∫ng",
            "true_false": "ƒê√∫ng ho·∫∑c Sai",
            "fill_blank": "ƒêi·ªÅn t·ª´/c·ª•m t·ª´ v√†o ch·ªó tr·ªëng",
            "short_answer": "Tr·∫£ l·ªùi ng·∫Øn 2-3 c√¢u",
            "essay": "T·ª± lu·∫≠n chi ti·∫øt"
        }
        
        prompt = f"""Sinh {item.n_questions} c√¢u h·ªèi cho:
- Ch·ªß ƒë·ªÅ: {topic_name}
- M·ª©c ƒë·ªô: {item.cognitive_level}
- ƒê·ªô kh√≥: {item.difficulty}
- Lo·∫°i: {item.type} ({type_instructions.get(item.type, '')})
- ƒêi·ªÉm m·ªói c√¢u: {item.points_each}

NG·ªÆ LI·ªÜU THAM KH·∫¢O:
{context[:2000] if context else 'Kh√¥ng c√≥'}

Y√äU C·∫¶U:
- C√¢u h·ªèi r√µ r√†ng, kh√¥ng m∆° h·ªì
- ƒê√°p √°n ch√≠nh x√°c, c√≥ cƒÉn c·ª©
- V·ªõi t·ª± lu·∫≠n: cung c·∫•p rubric chi ti·∫øt

Tr·∫£ v·ªÅ JSON:
{{
  "questions": [
    {{
      "stem": "C√¢u h·ªèi...",
      "options": ["A. ...", "B. ...", "C. ...", "D. ..."],  # n·∫øu l√† MCQ
      "answer": "B",  # ho·∫∑c text v·ªõi t·ª± lu·∫≠n
      "explanation": "Gi·∫£i th√≠ch...",
      "rubric": {{  # ch·ªâ cho t·ª± lu·∫≠n
        "criteria": [
          {{"description": "Tr√¨nh b√†y ƒë√∫ng c√¥ng th·ª©c", "points": 0.5}},
          {{"description": "T√≠nh to√°n ch√≠nh x√°c", "points": 0.5}}
        ]
      }}
    }}
  ]
}}
"""
        return prompt
