"""
Module sinh blueprint, matrix vÃ  cÃ¢u há»i báº±ng OpenAI
"""
import json
from typing import List, Dict, Any
from loguru import logger
from openai import OpenAI

from .models import (
    Blueprint, Topic, LearningOutcome, SourceTrace,
    ExamMatrix, MatrixItem, GlobalConfig, CognitiveRatios, DifficultyRatios,
    Question, QuestionRubric, Exam, Chunk
)
from .config import get_config
from .rag_indexer import RAGIndexer


class BlueprintGenerator:
    """Sinh blueprint kiáº¿n thá»©c tá»« Ä‘á» cÆ°Æ¡ng"""
    
    def __init__(self, client: OpenAI = None):
        config = get_config()
        self.client = client or OpenAI()
        self.model = config.openai_model
        self.temperature = config.temperature
    
    def generate(
        self,
        chunks: List[Chunk],
        subject: str = None,
        grade: int = None
    ) -> Blueprint:
        """
        Sinh blueprint tá»« chunks
        
        Args:
            chunks: CÃ¡c chunks chá»©a ná»™i dung Ä‘á» cÆ°Æ¡ng
            subject: MÃ´n há»c
            grade: Khá»‘i
            
        Returns:
            Blueprint object
        """
        logger.info("ðŸ§  Äang sinh blueprint tá»« Ä‘á» cÆ°Æ¡ng...")
        
        # Combine text from chunks
        full_text = "\n\n".join([f"[Trang {c.page}] {c.text}" for c in chunks])
        
        # Create prompt
        prompt = self._create_blueprint_prompt(full_text, subject, grade)
        
        # Call OpenAI
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch Ä‘á» cÆ°Æ¡ng giÃ¡o dá»¥c Viá»‡t Nam. Tráº£ vá» JSON Ä‘Ãºng format, khÃ´ng giáº£i thÃ­ch thÃªm."
                    },
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.3
            )
            
            # Parse response
            result = json.loads(response.choices[0].message.content)
            blueprint = self._parse_blueprint_response(result, subject, grade, chunks)
            
            logger.info(f"âœ… ÄÃ£ sinh blueprint vá»›i {len(blueprint.topics)} chá»§ Ä‘á»")
            return blueprint
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i khi sinh blueprint: {e}")
            raise
    
    def _create_blueprint_prompt(
        self,
        text: str,
        subject: str = None,
        grade: int = None
    ) -> str:
        """Táº¡o prompt Ä‘á»ƒ sinh blueprint"""
        
        prompt = f"""PhÃ¢n tÃ­ch Ä‘á» cÆ°Æ¡ng/káº¿ hoáº¡ch kiá»ƒm tra sau vÃ  trÃ­ch xuáº¥t:

1. **CÃ¡c chÆ°Æ¡ng/chá»§ Ä‘á» chÃ­nh** Ä‘Æ°á»£c Ä‘á» cáº­p
2. **YÃªu cáº§u cáº§n Ä‘áº¡t (learning outcomes)** cho má»—i chá»§ Ä‘á»
3. **Tá»« khÃ³a** vÃ  khÃ¡i niá»‡m quan trá»ng
4. **Má»©c Ä‘á»™ nháº­n thá»©c** gá»£i Ã½ cho má»—i outcome

Äá»€ CÆ¯Æ NG:
{text[:8000]}

HÆ¯á»šNG DáºªN OUTPUT:
- Má»—i outcome pháº£i cÃ³ **Ä‘á»™ng tá»« hÃ nh Ä‘á»™ng** rÃµ rÃ ng (VD: nháº­n biáº¿t, giáº£i thÃ­ch, giáº£i, phÃ¢n tÃ­ch, váº­n dá»¥ng...)
- Gá»£i Ã½ má»©c Ä‘á»™ theo Bloom: biet (biáº¿t), hieu (hiá»ƒu), vandung (váº­n dá»¥ng), vandungcao (váº­n dá»¥ng cao)
- TrÃ­ch xuáº¥t chÃ­nh xÃ¡c tá»« Ä‘á» cÆ°Æ¡ng, khÃ´ng bá»‹a

Tráº£ vá» JSON theo format sau:

{{
  "subject": "{subject or 'TÃªn mÃ´n há»c'}",
  "grade": {grade if grade else 'null'},
  "term": "Há»c ká»³ I hoáº·c II (náº¿u cÃ³ trong Ä‘á» cÆ°Æ¡ng)",
  "topics": [
    {{
      "topic_id": "T1",
      "name": "TÃªn chÆ°Æ¡ng/chá»§ Ä‘á» chÃ­nh",
      "outcomes": [
        {{
          "outcome_id": "O1",
          "verb": "giáº£i",
          "statement": "Giáº£i há»‡ phÆ°Æ¡ng trÃ¬nh báº­c nháº¥t hai áº©n báº±ng phÆ°Æ¡ng phÃ¡p tháº¿",
          "cognitive_level_hint": ["biet", "hieu"]
        }},
        {{
          "outcome_id": "O2",
          "verb": "váº­n dá»¥ng",
          "statement": "Váº­n dá»¥ng giáº£i bÃ i toÃ¡n thá»±c táº¿",
          "cognitive_level_hint": ["vandung"]
        }}
      ],
      "keywords": ["há»‡ phÆ°Æ¡ng trÃ¬nh", "phÆ°Æ¡ng phÃ¡p tháº¿", "phÆ°Æ¡ng phÃ¡p cá»™ng"],
      "subtopics": ["Há»‡ phÆ°Æ¡ng trÃ¬nh tÆ°Æ¡ng Ä‘Æ°Æ¡ng", "Giáº£i há»‡ báº±ng Ä‘á»“ thá»‹"]
    }}
  ]
}}
"""
        return prompt
    
    def _parse_blueprint_response(
        self,
        result: Dict[str, Any],
        subject: str,
        grade: int,
        chunks: List[Chunk]
    ) -> Blueprint:
        """Parse response thÃ nh Blueprint object"""
        
        topics = []
        for topic_data in result.get("topics", []):
            outcomes = []
            for outcome_data in topic_data.get("outcomes", []):
                # Táº¡o source trace Ä‘Æ¡n giáº£n (sáº½ cáº£i thiá»‡n sau vá»›i RAG)
                source_trace = [
                    SourceTrace(
                        chunk_id=chunks[0].chunk_id if chunks else "unknown",
                        page=chunks[0].page if chunks else 1
                    )
                ]
                
                outcomes.append(LearningOutcome(
                    outcome_id=outcome_data.get("outcome_id", ""),
                    verb=outcome_data.get("verb", ""),
                    statement=outcome_data.get("statement", ""),
                    cognitive_level_hint=outcome_data.get("cognitive_level_hint", []),
                    source_trace=source_trace
                ))
            
            topics.append(Topic(
                topic_id=topic_data.get("topic_id", ""),
                name=topic_data.get("name", ""),
                outcomes=outcomes,
                keywords=topic_data.get("keywords", []),
                subtopics=topic_data.get("subtopics", [])
            ))
        
        return Blueprint(
            subject=result.get("subject", subject or ""),
            grade=result.get("grade", grade),
            term=result.get("term"),
            topics=topics
        )


class MatrixGenerator:
    """Sinh ma tráº­n Ä‘á» kiá»ƒm tra theo CV 7991"""
    
    def __init__(self, client: OpenAI = None):
        config = get_config()
        self.client = client or OpenAI()
        self.model = config.openai_model
        self.temperature = config.temperature
    
    def generate(
        self,
        blueprint: Blueprint,
        global_config: GlobalConfig,
        cognitive_ratios: CognitiveRatios,
        difficulty_ratios: DifficultyRatios
    ) -> ExamMatrix:
        """
        Sinh ma tráº­n tá»« blueprint
        
        Args:
            blueprint: Blueprint kiáº¿n thá»©c
            global_config: Cáº¥u hÃ¬nh chung (thá»i gian, tá»•ng Ä‘iá»ƒm...)
            cognitive_ratios: Tá»· lá»‡ má»©c Ä‘á»™ nháº­n thá»©c
            difficulty_ratios: Tá»· lá»‡ Ä‘á»™ khÃ³
            
        Returns:
            ExamMatrix object
        """
        logger.info("ðŸ“Š Äang sinh ma tráº­n Ä‘á» kiá»ƒm tra...")
        
        # Create prompt
        prompt = self._create_matrix_prompt(
            blueprint,
            global_config,
            cognitive_ratios,
            difficulty_ratios
        )
        
        try:
            # Call OpenAI
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Báº¡n lÃ  chuyÃªn gia thiáº¿t káº¿ ma tráº­n Ä‘á» kiá»ƒm tra theo quy Ä‘á»‹nh cá»§a Bá»™ GD&ÄT Viá»‡t Nam. Tráº£ vá» JSON Ä‘Ãºng format."
                    },
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.3
            )
            
            result = json.loads(response.choices[0].message.content)
            matrix = self._parse_matrix_response(result, global_config, cognitive_ratios, difficulty_ratios)
            
            # Validate
            self._validate_matrix(matrix)
            
            logger.info(f"âœ… ÄÃ£ sinh ma tráº­n vá»›i {len(matrix.items_plan)} dÃ²ng")
            return matrix
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i khi sinh ma tráº­n: {e}")
            raise
    
    def _create_matrix_prompt(
        self,
        blueprint: Blueprint,
        global_config: GlobalConfig,
        cognitive_ratios: CognitiveRatios,
        difficulty_ratios: DifficultyRatios
    ) -> str:
        """Táº¡o prompt sinh ma tráº­n"""
        
        # Tá»•ng há»£p topics
        topics_detail = []
        for t in blueprint.topics:
            outcomes_str = "\n    ".join([
                f"+ {o.outcome_id}: {o.statement} (má»©c Ä‘á»™ gá»£i Ã½: {', '.join(o.cognitive_level_hint)})"
                for o in t.outcomes
            ])
            topics_detail.append(f"  {t.topic_id}: {t.name}\n    {outcomes_str}")
        
        topics_summary = "\n".join(topics_detail)
        
        prompt = f"""Thiáº¿t káº¿ ma tráº­n Ä‘á» kiá»ƒm tra (Matrix + Báº£ng Ä‘áº·c táº£) cho Ä‘á» kiá»ƒm tra {blueprint.subject} lá»›p {blueprint.grade}.

CÃC CHá»¦ Äá»€ VÃ€ YÃŠU Cáº¦U Cáº¦N Äáº T:
{topics_summary}

YÃŠU Cáº¦U CHUNG:
- Thá»i gian: {global_config.time_minutes} phÃºt
- Tá»•ng Ä‘iá»ƒm: {global_config.total_points} Ä‘iá»ƒm
- Tá»· lá»‡ tráº¯c nghiá»‡m: {global_config.mcq_ratio * 100:.0f}%
- Tá»· lá»‡ tá»± luáº­n: {global_config.essay_ratio * 100:.0f}%

Tá»¶ Lá»† Má»¨C Äá»˜ NHáº¬N THá»¨C (Bloom):
- Biáº¿t (biet): {cognitive_ratios.biet * 100:.0f}%
- Hiá»ƒu (hieu): {cognitive_ratios.hieu * 100:.0f}%
- Váº­n dá»¥ng (vandung): {cognitive_ratios.vandung * 100:.0f}%
- Váº­n dá»¥ng cao (vandungcao): {cognitive_ratios.vandungcao * 100:.0f}%

Tá»¶ Lá»† Äá»˜ KHÃ“:
- Dá»… (de): {difficulty_ratios.de * 100:.0f}%
- Trung bÃ¬nh (tb): {difficulty_ratios.tb * 100:.0f}%
- KhÃ³ (kho): {difficulty_ratios.kho * 100:.0f}%

LOáº I CÃ‚U Há»ŽI:
- mcq_single: Tráº¯c nghiá»‡m 1 Ä‘Ã¡p Ã¡n Ä‘Ãºng (4 lá»±a chá»n A/B/C/D)
- mcq_multiple: Tráº¯c nghiá»‡m nhiá»u Ä‘Ã¡p Ã¡n Ä‘Ãºng
- true_false: ÄÃºng/Sai
- short_answer: Tá»± luáº­n ngáº¯n (1-3 cÃ¢u)
- essay: Tá»± luáº­n dÃ i (cÃ³ rubric chi tiáº¿t)

Tráº£ vá» JSON theo format:
{{
  "items_plan": [
    {{
      "row_id": "R1",
      "topic_id": "T1",
      "outcome_ids": ["O1"],
      "cognitive_level": "biet",
      "difficulty": "de",
      "type": "mcq_single",
      "n_questions": 4,
      "points_each": 0.25
    }},
    {{
      "row_id": "R2",
      "topic_id": "T1",
      "outcome_ids": ["O2", "O3"],
      "cognitive_level": "vandung",
      "difficulty": "kho",
      "type": "essay",
      "n_questions": 1,
      "points_each": 2.0
    }}
  ]
}}

YÃŠU Cáº¦U:
1. Tá»•ng Ä‘iá»ƒm cÃ¡c cÃ¢u PHáº¢I Báº°NG {global_config.total_points}
2. PhÃ¢n bá»• Ä‘á»u cÃ¡c topic
3. Tá»· lá»‡ má»©c Ä‘á»™ vÃ  Ä‘á»™ khÃ³ gáº§n Ä‘Ãºng yÃªu cáº§u
4. CÃ¢u tráº¯c nghiá»‡m thÆ°á»ng 0.25-0.5 Ä‘iá»ƒm/cÃ¢u
5. CÃ¢u tá»± luáº­n 1-3 Ä‘iá»ƒm/cÃ¢u
"""
        return prompt
    
    def _parse_matrix_response(
        self,
        result: Dict[str, Any],
        global_config: GlobalConfig,
        cognitive_ratios: CognitiveRatios,
        difficulty_ratios: DifficultyRatios
    ) -> ExamMatrix:
        """Parse response thÃ nh ExamMatrix"""
        
        items = []
        for item_data in result.get("items_plan", []):
            items.append(MatrixItem(
                row_id=item_data.get("row_id", ""),
                topic_id=item_data.get("topic_id", ""),
                outcome_ids=item_data.get("outcome_ids", []),
                cognitive_level=item_data.get("cognitive_level", "biet"),
                difficulty=item_data.get("difficulty", "tb"),
                type=item_data.get("type", "mcq_single"),
                n_questions=item_data.get("n_questions", 1),
                points_each=item_data.get("points_each", 0.25),
                source_trace=[]
            ))
        
        return ExamMatrix(
            global_config=global_config,
            cognitive_ratios=cognitive_ratios,
            difficulty_ratios=difficulty_ratios,
            items_plan=items
        )
    
    def _validate_matrix(self, matrix: ExamMatrix):
        """Kiá»ƒm tra tÃ­nh há»£p lá»‡ cá»§a ma tráº­n"""
        total_points = sum(item.n_questions * item.points_each for item in matrix.items_plan)
        
        if abs(total_points - matrix.global_config.total_points) > 0.5:
            logger.warning(
                f"âš ï¸ Tá»•ng Ä‘iá»ƒm ({total_points}) khÃ´ng khá»›p vá»›i yÃªu cáº§u ({matrix.global_config.total_points})"
            )


class QuestionGenerator:
    """Sinh cÃ¢u há»i tá»« ma tráº­n + RAG"""
    
    def __init__(self, client: OpenAI = None, indexer: RAGIndexer = None):
        config = get_config()
        self.client = client or OpenAI()
        self.model = config.openai_model
        self.temperature = config.temperature
        self.top_k = config.top_k
        self.indexer = indexer
    
    def generate_exam(
        self,
        matrix: ExamMatrix,
        blueprint: Blueprint
    ) -> Exam:
        """
        Sinh Ä‘á» thi tá»« ma tráº­n
        
        Args:
            matrix: Ma tráº­n Ä‘á»
            blueprint: Blueprint kiáº¿n thá»©c
            
        Returns:
            Exam object
        """
        logger.info(f"ðŸ“ Äang sinh {sum(item.n_questions for item in matrix.items_plan)} cÃ¢u há»i...")
        
        all_questions = []
        
        for item in matrix.items_plan:
            # Láº¥y topic vÃ  outcomes
            topic = self._get_topic(blueprint, item.topic_id)
            outcomes = [self._get_outcome(topic, oid) for oid in item.outcome_ids if topic]
            
            # Generate N questions cho item nÃ y
            for i in range(item.n_questions):
                question = self._generate_single_question(item, topic, outcomes, i + 1)
                all_questions.append(question)
        
        exam = Exam(questions=all_questions)
        logger.info(f"âœ… ÄÃ£ sinh {len(all_questions)} cÃ¢u há»i")
        return exam
    
    def _generate_single_question(
        self,
        item: MatrixItem,
        topic: Topic,
        outcomes: List[LearningOutcome],
        question_number: int
    ) -> Question:
        """Sinh 1 cÃ¢u há»i"""
        
        # Retrieve context tá»« RAG
        context_chunks = []
        if self.indexer:
            query = f"{topic.name if topic else ''} {' '.join([o.statement for o in outcomes if o])}"
            context_chunks = self.indexer.search(query, top_k=self.top_k)
        
        context_text = "\n\n".join([f"[Trang {c.page}] {c.text[:500]}" for c in context_chunks[:3]])
        
        # Create prompt
        prompt = self._create_question_prompt(item, topic, outcomes, context_text)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Báº¡n lÃ  chuyÃªn gia ra Ä‘á» kiá»ƒm tra giÃ¡o dá»¥c Viá»‡t Nam. Sinh cÃ¢u há»i cháº¥t lÆ°á»£ng cao, tráº£ vá» JSON."
                    },
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=self.temperature
            )
            
            result = json.loads(response.choices[0].message.content)
            question = self._parse_question_response(result, item, context_chunks)
            
            return question
            
        except Exception as e:
            logger.error(f"âŒ Lá»—i sinh cÃ¢u {item.row_id}: {e}")
            # Return fallback question
            return self._create_fallback_question(item)
    
    def _create_question_prompt(
        self,
        item: MatrixItem,
        topic: Topic,
        outcomes: List[LearningOutcome],
        context: str
    ) -> str:
        """Táº¡o prompt sinh cÃ¢u há»i"""
        
        outcomes_str = "\n".join([f"- {o.statement}" for o in outcomes if o])
        
        type_instructions = {
            "mcq_single": "Tráº¯c nghiá»‡m 1 Ä‘Ã¡p Ã¡n Ä‘Ãºng, 4 lá»±a chá»n A/B/C/D. CÃ¡c Ä‘Ã¡p Ã¡n sai pháº£i há»£p lÃ½, khÃ´ng rÃµ rÃ ng sai.",
            "essay": "Tá»± luáº­n cÃ³ rubric chi tiáº¿t (tiÃªu chÃ­ cháº¥m Ä‘iá»ƒm).",
            "short_answer": "Tá»± luáº­n ngáº¯n, Ä‘Ã¡p Ã¡n 1-3 cÃ¢u."
        }
        
        prompt = f"""Sinh cÃ¢u há»i kiá»ƒm tra vá»›i yÃªu cáº§u sau:

CHá»¦ Äá»€: {topic.name if topic else 'KhÃ´ng rÃµ'}
YÃŠU Cáº¦U Cáº¦N Äáº T:
{outcomes_str}

LOáº I CÃ‚U Há»ŽI: {item.type}
Má»¨C Äá»˜: {item.cognitive_level}
Äá»˜ KHÃ“: {item.difficulty}
ÄIá»‚M: {item.points_each}

HÆ¯á»šNG DáºªN: {type_instructions.get(item.type, '')}

NGá»® LIá»†U THAM KHáº¢O:
{context[:2000] if context else '(KhÃ´ng cÃ³ ngá»¯ liá»‡u)'}

Tráº£ vá» JSON:
{{
  "stem": "Ná»™i dung cÃ¢u há»i (rÃµ rÃ ng, Ä‘áº§y Ä‘á»§ ngá»¯ cáº£nh)",
  "options": ["A. ...", "B. ...", "C. ...", "D. ..."],  // Chá»‰ cho MCQ
  "answer": "B",  // Hoáº·c Ä‘Ã¡p Ã¡n Ä‘Ãºng cho tá»± luáº­n
  "explanation": "Giáº£i thÃ­ch táº¡i sao Ä‘Ã¡p Ã¡n nÃ y Ä‘Ãºng",
  "rubric": null  // Hoáº·c object {{criteria: [...], max_score: ...}} cho essay
}}

YÃŠU Cáº¦U:
- CÃ¢u há»i pháº£i dá»±a vÃ o ngá»¯ liá»‡u (khÃ´ng bá»‹a)
- ÄÃºng má»©c Ä‘á»™ nháº­n thá»©c: {item.cognitive_level}
- RÃµ rÃ ng, khÃ´ng mÆ¡ há»“
- PhÃ¹ há»£p há»c sinh lá»›p nÃ y
"""
        return prompt
    
    def _parse_question_response(
        self,
        result: Dict[str, Any],
        item: MatrixItem,
        context_chunks: List[Chunk]
    ) -> Question:
        """Parse response thÃ nh Question"""
        
        # Táº¡o source trace
        source_trace = []
        if context_chunks:
            source_trace = [
                SourceTrace(chunk_id=c.chunk_id, page=c.page, section=c.section)
                for c in context_chunks[:2]
            ]
        
        # Parse rubric náº¿u cÃ³
        rubric = None
        if result.get("rubric") and isinstance(result["rubric"], dict):
            rubric = QuestionRubric(
                criteria=result["rubric"].get("criteria", []),
                max_score=result["rubric"].get("max_score", item.points_each)
            )
        
        return Question(
            id=f"{item.row_id}_Q1",
            type=item.type,
            topic_id=item.topic_id,
            cognitive_level=item.cognitive_level,
            difficulty=item.difficulty,
            stem=result.get("stem", ""),
            options=result.get("options", []),
            answer=result.get("answer", ""),
            explanation=result.get("explanation", ""),
            points=item.points_each,
            rubric=rubric,
            source_trace=source_trace
        )
    
    def _create_fallback_question(self, item: MatrixItem) -> Question:
        """Táº¡o cÃ¢u há»i dá»± phÃ²ng náº¿u AI fail"""
        return Question(
            id=f"{item.row_id}_Q1",
            type=item.type,
            topic_id=item.topic_id,
            cognitive_level=item.cognitive_level,
            difficulty=item.difficulty,
            stem="[CÃ¢u há»i chÆ°a sinh Ä‘Æ°á»£c - cáº§n review]",
            options=[],
            answer="",
            explanation="",
            points=item.points_each,
            source_trace=[]
        )
    
    def _get_topic(self, blueprint: Blueprint, topic_id: str) -> Topic:
        """Láº¥y topic theo ID"""
        for topic in blueprint.topics:
            if topic.topic_id == topic_id:
                return topic
        return None
    
    def _get_outcome(self, topic: Topic, outcome_id: str) -> LearningOutcome:
        """Láº¥y outcome theo ID"""
        if not topic:
            return None
        for outcome in topic.outcomes:
            if outcome.outcome_id == outcome_id:
                return outcome
        return None
